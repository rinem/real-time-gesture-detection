{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np # We'll be storing our data as numpy arrays\n",
    "import os # For handling directories\n",
    "from PIL import Image # For handling the images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg # Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\gesture-recognition'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "for j in os.listdir('data/'):\n",
    "    if not j.startswith('.'): # If running this code locally, this is to \n",
    "                              # ensure you aren't reading in hidden folders\n",
    "        lookup[j] = count\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fist': 0, 'L': 1, 'none': 2, 'ok': 3, 'palm': 4, 'peace': 5, 'thumbsup': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'fist', 1: 'L', 2: 'none', 3: 'ok', 4: 'palm', 5: 'peace', 6: 'thumbsup'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverselookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "datacount = 0 \n",
    " # Loop over the ten top-level folders\n",
    "for j in os.listdir('data/'):\n",
    "    if not j.startswith('.'): # Again avoid hidden folders\n",
    "        count = 0 # To tally images of a given gesture\n",
    "        for k in os.listdir('data/' + j + '/'):\n",
    "                            # Loop over the images\n",
    "            img = Image.open('data/' + j + '/' + k)\n",
    "                            # Read in and convert to greyscale\n",
    "            arr = np.array(img)\n",
    "            x_data.append(arr) \n",
    "            count = count + 1\n",
    "        y_values = np.full((count, 1), lookup[j]) \n",
    "        y_data.append(y_values)\n",
    "        datacount = datacount + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(x_data, dtype = 'float32')\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(datacount, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 300, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\mltensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\mltensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\mltensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\mltensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\mltensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\mltensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 300, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = x_data.reshape((datacount, 300, 300, 1))\n",
    "x_data /= 255\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.1)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(300, 300,1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2367616   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,424,775\n",
      "Trainable params: 2,424,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 84 samples\n",
      "Epoch 1/10\n",
      "1890/1890 [==============================] - 66s 35ms/step - loss: 0.8038 - acc: 0.7640 - val_loss: 0.1302 - val_acc: 0.9524\n",
      "Epoch 2/10\n",
      "1890/1890 [==============================] - 73s 39ms/step - loss: 0.0901 - acc: 0.9751 - val_loss: 0.0883 - val_acc: 0.9762\n",
      "Epoch 3/10\n",
      "1890/1890 [==============================] - 70s 37ms/step - loss: 0.0162 - acc: 0.9958 - val_loss: 0.2047 - val_acc: 0.9524\n",
      "Epoch 4/10\n",
      "1890/1890 [==============================] - 66s 35ms/step - loss: 0.0102 - acc: 0.9963 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "1890/1890 [==============================] - 65s 35ms/step - loss: 6.0277e-05 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      "1890/1890 [==============================] - 65s 34ms/step - loss: 8.9510e-06 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "1890/1890 [==============================] - 77s 41ms/step - loss: 1.5860e-06 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9881\n",
      "Epoch 8/10\n",
      "1890/1890 [==============================] - 83s 44ms/step - loss: 3.9484e-07 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9881\n",
      "Epoch 9/10\n",
      "1890/1890 [==============================] - 84s 44ms/step - loss: 1.7219e-07 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 0.9881\n",
      "Epoch 10/10\n",
      "1890/1890 [==============================] - 85s 45ms/step - loss: 1.3192e-07 - acc: 1.0000 - val_loss: 0.0680 - val_acc: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fe2bb9f98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 11ms/step\n",
      "Accuracy:0.9880952380952381\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = model.evaluate(x_validate,y_validate,verbose=1)\n",
    "print(\"Accuracy:\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = Image.open('test/4.png')\n",
    "a = np.array(new)\n",
    "a = a/255\n",
    "a = a.reshape(1, 300, 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.48361671e-17, 5.71457443e-21, 3.33096848e-21, 1.00000000e+00,\n",
       "        9.00522538e-12, 4.96676593e-13, 1.35628256e-17]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fist': 0, 'L': 1, 'none': 2, 'ok': 3, 'palm': 4, 'peace': 5, 'thumbsup': 6}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y, x in lookup.items():\n",
    "    label[x] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'fist', 1: 'L', 2: 'none', 3: 'ok', 4: 'palm', 5: 'peace', 6: 'thumbsup'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.where(result[0] == np.amax(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(label[l[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(result[0][l][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
